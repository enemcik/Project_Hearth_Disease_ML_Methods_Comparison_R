roc.perf_nn = performance(pred_nn, measure = "tpr", x.measure = "fpr") #performance measure as ROC
auc.perf_nn = performance(pred_nn, measure = "auc") #performance measure AUC
auc_nn[i] = auc.perf_nn@y.values[[1]]
acc.perf_nn = performance(pred_nn, measure = "acc") # find best cutoff according to accuracy
ind_nn = which.max( slot(acc.perf_nn, "y.values")[[1]] )
acc_nn[i] = slot(acc.perf_nn, "y.values")[[1]][ind_nn]
cutoff_nn = slot(acc.perf_nn, "x.values")[[1]][ind_nn]
cut_nn[i] = cutoff_nn
pred_nn = as.numeric(prob_nn > cutoff_nn) #ERROR- minimized by maximizing ACCURACY using its cutoff
er_nn[i] = mean(pred_nn != val_data$target)
},TRUE)
##BOOSTED TREE
sparse_matrix = sparse.model.matrix(target ~ ., data = train_data)[,-1] #dummy contrast coding of categorical variables to fit the xgboost
sparse_matrix_val = sparse.model.matrix(target ~ ., data = val_data[,colnames(train_data)])[,-1]
labels = train_data$target
bst = xgboost(data = sparse_matrix, label = labels, max_depth = 4,
eta = 1, nthread = 2, nrounds = 10,objective = "binary:logistic")
importance = xgb.importance(feature_names = colnames(sparse_matrix), model = bst) #importance of features
head(importance)
try({
prob_xgboost = predict(bst, sparse_matrix_val)
pred_xgboost = prediction(prob_xgboost, val_data$target) #create a prediction object with true values and predicted ones
roc.perf_xgboost = performance(pred_xgboost, measure = "tpr", x.measure = "fpr") #performance measure as ROC
auc.perf_xgboost= performance(pred_xgboost, measure = "auc") #performance measure AUC
auc_xgboost[i] = auc.perf_xgboost@y.values[[1]]
acc.perf_xgboost = performance(pred_xgboost, measure = "acc") # find best cutoff according to accuracy
ind_xgboost = which.max( slot(acc.perf_xgboost, "y.values")[[1]] )
acc_xgboost[i] = slot(acc.perf_xgboost, "y.values")[[1]][ind_xgboost]
cutoff_xgboost = slot(acc.perf_xgboost, "x.values")[[1]][ind_xgboost]
cut_xgboost[i] = cutoff_xgboost
pred_xgboost = as.numeric(prob_xgboost > cutoff_xgboost) #ERROR- minimized by maximizing ACCURACY using its cutoff
er_xgboost[i] = mean(pred_xgboost != val_data$target)
},TRUE)
}
print(mean(acc_log, na.rm = TRUE))
####DATA HANDLING/INSPECTION
data = read.csv("heart.csv")
data = as.data.frame(data)
head(data,5)
data$sex = as.factor(data$sex) #gender
data$cp = as.factor(data$cp) #chest pain
data$fbs = as.factor(data$fbs) #fasting blood sugar
data$restecg = as.factor(data$restecg) #resting ECG
data$exang = as.factor(data$exang) # induced angina
data$slope = as.factor(data$slope) #slope
data$ca = as.factor(data$ca) #number of colored vessels
data$thal = as.factor(data$thal) #thal
str(data) #variables
summary(data) #variable statistics
sapply(data, sd)
apply(data, 2, function(x) {sum(is.na(x))}) #NAs inspection, 0 present
data_cv = data #cross-validation
set.seed(935) #for reproducibility
n = nrow(data) #shuffling the data
data = data[sample(n),]
rand_rows = sample(1:nrow(data), 0.6*nrow(data)) #split into training and validation dataset
train_data = data[rand_rows, ]
val_data = data[-rand_rows, ]
vars = colnames(data)[-length(colnames(data))] #creating a formula
y = "target"
fmla = paste(y, paste(vars, collapse="+"),sep="~")
fmla
######################
####Cross-validated###
######################
k = 100
acc_log = NULL
acc_cart = NULL
acc_nn = NULL
acc_xgboost = NULL
er_log = NULL
er_cart = NULL
er_nn = NULL
er_xgboost = NULL
ac_log = NULL
ac_cart = NULL
ac_nn = NULL
ac_xgboost = NULL
acc.bt.train=NULL
acc.bt.val= NULL
cut_log = NULL
cut_cart = NULL
cut_nn = NULL
cut_xgboost = NULL
cut_rf = NULL
set.seed(100)
for (i in 1:k){ #sample randomly 100 times
n = nrow(data_cv)
data_temp = data_cv[sample(n),]
rand_rows = sample(1:nrow(data_temp), 0.7*nrow(data_temp)) #split into training and validation dataset
train_data = data_temp[rand_rows, ]
val_data = data_temp[-rand_rows, ]
##LOGISTISTIC
logit = glm(fmla, data = train_data, family = "binomial")
try({
prob_log = predict(logit, val_data, type = "response")
pred_log = prediction(prob_log, val_data$target) #create a prediction object with true values and predicted ones
roc.perf_log = performance(pred_log, measure = "tpr", x.measure = "fpr") #performance measure as ROC
auc.perf_log = performance(pred_log, measure = "auc") #performance measure AUC
auc_log[i] = auc.perf_log@y.values[[1]]
acc.perf_log = performance(pred_log, measure = "acc") # find best cutoff according to accuracy
ind_log = which.max( slot(acc.perf_log, "y.values")[[1]] )
acc_log[i] = slot(acc.perf_log, "y.values")[[1]][ind_log]
cutoff_log = slot(acc.perf_log, "x.values")[[1]][ind_log]
cut_log[i] = cutoff_log
pred_log = as.numeric(prob_log > cutoff_log) #ERROR- minimized by maximizing ACCURACY using its cutoff
er_log[i] = mean(pred_log != val_data$target)
},TRUE)
##DECISION TREE - BAGGED
m<-dim(train_data)[1]
ntree<-33
samples<-sapply(1:ntree,
FUN = function(iter)
{sample(1:m, size=m, replace=T)}) #replace=T makes it a bootstrap
try({
treelist<-lapply(1:ntree, #Training the individual decision trees and return them in a list
FUN=function(iter) {
samp <- samples[,iter];
rpart(fmla,train_data[samp,])
}
)
#predict.bag assumes the underlying classifier returns decision probabilities, not decisions.
predict.bag<-function(treelist,newdata) {
preds<-sapply(1:length(treelist),
FUN=function(iter) {
predict(treelist[[iter]],newdata=newdata)
}
)
predsums<-rowSums(preds)
predsums/length(treelist)
}
prob_bagtree = predict.bag(treelist, newdata=val_data)
pred_bagtree = prediction(prob_bagtree, val_data$target)
roc.perf_bagtree = performance(pred_bagtree, measure = "tpr", x.measure = "fpr") #performance measure as ROC
auc.perf_bagtree = performance(pred_bagtree, measure = "auc") #performance measure AUC
auc_cart[i] = auc.perf_bagtree@y.values[[1]]
acc.perf_bagtree = performance(pred_bagtree, measure = "acc") # find best cutoff according to accuracy
ind_bagtree = which.max( slot(acc.perf_bagtree, "y.values")[[1]] )
acc_cart[i] = slot(acc.perf_bagtree, "y.values")[[1]][ind_bagtree]
cutoff_bagtree = slot(acc.perf_bagtree, "x.values")[[1]][ind_bagtree]
cut_cart[i] = cutoff_bagtree
pred_bagtree = as.numeric(prob_bagtree > cutoff_bagtree) #ERROR- minimized by maximizing ACCURACY using its cutoff
er_cart[i] = mean(pred_bagtree != val_data$target)
},TRUE)
##NEURAL NET
nn = nnet(target~Ã¯..age+sex+cp+trestbps+chol+fbs+restecg+thalach
+exang+oldpeak+slope+ca+thal, data = train_data, size = 5, decay = 5e-4, maxit = 100)
try({
prob_nn = predict(nn, val_data)
pred_nn = prediction(prob_nn, val_data$target) #create a prediction object with true values and predicted ones
roc.perf_nn = performance(pred_nn, measure = "tpr", x.measure = "fpr") #performance measure as ROC
auc.perf_nn = performance(pred_nn, measure = "auc") #performance measure AUC
auc_nn[i] = auc.perf_nn@y.values[[1]]
acc.perf_nn = performance(pred_nn, measure = "acc") # find best cutoff according to accuracy
ind_nn = which.max( slot(acc.perf_nn, "y.values")[[1]] )
acc_nn[i] = slot(acc.perf_nn, "y.values")[[1]][ind_nn]
cutoff_nn = slot(acc.perf_nn, "x.values")[[1]][ind_nn]
cut_nn[i] = cutoff_nn
pred_nn = as.numeric(prob_nn > cutoff_nn) #ERROR- minimized by maximizing ACCURACY using its cutoff
er_nn[i] = mean(pred_nn != val_data$target)
},TRUE)
##BOOSTED TREE
sparse_matrix = sparse.model.matrix(target ~ ., data = train_data)[,-1] #dummy contrast coding of categorical variables to fit the xgboost
sparse_matrix_val = sparse.model.matrix(target ~ ., data = val_data[,colnames(train_data)])[,-1]
labels = train_data$target
bst = xgboost(data = sparse_matrix, label = labels, max_depth = 4,
eta = 1, nthread = 2, nrounds = 10,objective = "binary:logistic")
importance = xgb.importance(feature_names = colnames(sparse_matrix), model = bst) #importance of features
head(importance)
try({
prob_xgboost = predict(bst, sparse_matrix_val)
pred_xgboost = prediction(prob_xgboost, val_data$target) #create a prediction object with true values and predicted ones
roc.perf_xgboost = performance(pred_xgboost, measure = "tpr", x.measure = "fpr") #performance measure as ROC
auc.perf_xgboost= performance(pred_xgboost, measure = "auc") #performance measure AUC
auc_xgboost[i] = auc.perf_xgboost@y.values[[1]]
acc.perf_xgboost = performance(pred_xgboost, measure = "acc") # find best cutoff according to accuracy
ind_xgboost = which.max( slot(acc.perf_xgboost, "y.values")[[1]] )
acc_xgboost[i] = slot(acc.perf_xgboost, "y.values")[[1]][ind_xgboost]
cutoff_xgboost = slot(acc.perf_xgboost, "x.values")[[1]][ind_xgboost]
cut_xgboost[i] = cutoff_xgboost
pred_xgboost = as.numeric(prob_xgboost > cutoff_xgboost) #ERROR- minimized by maximizing ACCURACY using its cutoff
er_xgboost[i] = mean(pred_xgboost != val_data$target)
},TRUE)
}
print(mean(acc_log, na.rm = TRUE))
print(mean(acc_cart, na.rm = TRUE))
print(mean(acc_nn, na.rm = TRUE))
n = nrow(data_cv)
data_temp = data_cv[sample(n),]
rand_rows = sample(1:nrow(data_temp), 0.7*nrow(data_temp)) #split into training and validation dataset
train_data = data_temp[rand_rows, ]
val_data = data_temp[-rand_rows, ]
##LOGISTISTIC
logit = glm(fmla, data = train_data, family = "binomial")
try({
prob_log = predict(logit, val_data, type = "response")
pred_log = prediction(prob_log, val_data$target) #create a prediction object with true values and predicted ones
roc.perf_log = performance(pred_log, measure = "tpr", x.measure = "fpr") #performance measure as ROC
auc.perf_log = performance(pred_log, measure = "auc") #performance measure AUC
auc_log[i] = auc.perf_log@y.values[[1]]
acc.perf_log = performance(pred_log, measure = "acc") # find best cutoff according to accuracy
ind_log = which.max( slot(acc.perf_log, "y.values")[[1]] )
acc_log[i] = slot(acc.perf_log, "y.values")[[1]][ind_log]
cutoff_log = slot(acc.perf_log, "x.values")[[1]][ind_log]
cut_log[i] = cutoff_log
pred_log = as.numeric(prob_log > cutoff_log) #ERROR- minimized by maximizing ACCURACY using its cutoff
er_log[i] = mean(pred_log != val_data$target)
},TRUE)
acc_log
####DATA HANDLING/INSPECTION
data = read.csv("heart.csv")
data = as.data.frame(data)
head(data,5)
data$sex = as.factor(data$sex) #gender
data$cp = as.factor(data$cp) #chest pain
data$fbs = as.factor(data$fbs) #fasting blood sugar
data$restecg = as.factor(data$restecg) #resting ECG
data$slope = as.factor(data$slope) #slope
data$ca = as.factor(data$ca) #number of colored vessels
data$exang = as.factor(data$exang) # induced angina
data$thal = as.factor(data$thal) #thal
str(data) #variables
summary(data) #variable statistics
sapply(data, sd)
apply(data, 2, function(x) {sum(is.na(x))}) #NAs inspection, 0 present
data_cv = data #cross-validation
set.seed(935) #for reproducibility
n = nrow(data) #shuffling the data
data = data[sample(n),]
rand_rows = sample(1:nrow(data), 0.6*nrow(data)) #split into training and validation dataset
train_data = data[rand_rows, ]
val_data = data[-rand_rows, ]
vars = colnames(data)[-length(colnames(data))] #creating a formula
y = "target"
fmla = paste(y, paste(vars, collapse="+"),sep="~")
fmla
k = 100
acc_log = NULL
acc_cart = NULL
acc_nn = NULL
acc_xgboost = NULL
er_log = NULL
er_cart = NULL
er_nn = NULL
er_xgboost = NULL
ac_cart = NULL
ac_nn = NULL
ac_log = NULL
ac_xgboost = NULL
acc.bt.train=NULL
acc.bt.val= NULL
cut_log = NULL
cut_cart = NULL
cut_nn = NULL
cut_xgboost = NULL
cut_rf = NULL
set.seed(100)
n = nrow(data_cv)
data_temp = data_cv[sample(n),]
rand_rows = sample(1:nrow(data_temp), 0.7*nrow(data_temp)) #split into training and validation dataset
train_data = data_temp[rand_rows, ]
val_data = data_temp[-rand_rows, ]
##LOGISTISTIC
logit = glm(fmla, data = train_data, family = "binomial")
logit
prob_log = predict(logit, val_data, type = "response")
pred_log = prediction(prob_log, val_data$target) #create a prediction object with true values and predicted ones
roc.perf_log = performance(pred_log, measure = "tpr", x.measure = "fpr") #performance measure as ROC
auc.perf_log = performance(pred_log, measure = "auc") #performance measure AUC
prob_log = predict(logit, val_data, type = "response")
pred_log = prediction(prob_log, val_data$target) #create a prediction object with true values and predicted ones
val_data
val_data$target
pred_log = prediction(prob_log, val_data$target) #create a prediction object with true values and predicted ones
prediction(prob_log, val_data$target)
val_data$target
prob_log
library(party)
library(DiagrammeR)
library(GGally)
library(neuralnet)
library(foreign)
library(plyr)
library(MASS)
library(rms)
library(ROCR)
library(pROC)
library(rpart)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
library(e1071)
library(dplyr)
library(ggplot2)
library(tidyr)
library(tidyverse)
library(cluster)
library(factoextra)
library(xgboost)
library(Matrix)
library(mltools)
library(data.table)
library(DMwR)
library(zoo)
library(caret)
library(randomForest)
library(nnet)
####DATA HANDLING/INSPECTION
data = read.csv("heart.csv")
data = as.data.frame(data)
head(data,5)
data$sex = as.factor(data$sex) #gender
data$cp = as.factor(data$cp) #chest pain
data$fbs = as.factor(data$fbs) #fasting blood sugar
data$restecg = as.factor(data$restecg) #resting ECG
data$exang = as.factor(data$exang) # induced angina
data$slope = as.factor(data$slope) #slope
data$thal = as.factor(data$thal) #thal
str(data) #variables
summary(data) #variable statistics
set.seed(935) #for reproducibility
rand_rows = sample(1:nrow(data), 0.6*nrow(data)) #split into training and validation dataset
train_data = data[rand_rows, ]
vars = colnames(data)[-length(colnames(data))] #creating a formula
y = "target"
fmla = paste(y, paste(vars, collapse="+"),sep="~")
fmla
k = 100
acc_log = NULL
data_cv = data #cross-validation
data$ca = as.factor(data$ca) #number of colored vessels
acc_cart = NULL
n = nrow(data) #shuffling the data
acc_nn = NULL
acc_xgboost = NULL
sapply(data, sd)
er_log = NULL
er_cart = NULL
er_nn = NULL
er_xgboost = NULL
apply(data, 2, function(x) {sum(is.na(x))}) #NAs inspection, 0 present
ac_log = NULL
data = data[sample(n),]
ac_cart = NULL
ac_nn = NULL
ac_xgboost = NULL
val_data = data[-rand_rows, ]
acc.bt.train=NULL
acc.bt.val= NULL
cut_log = NULL
cut_nn = NULL
cut_xgboost = NULL
cut_cart = NULL
cut_rf = NULL
set.seed(100)
for (i in 1:k){ #sample randomly 100 times
n = nrow(data_cv)
data_temp = data_cv[sample(n),]
rand_rows = sample(1:nrow(data_temp), 0.7*nrow(data_temp)) #split into training and validation dataset
train_data = data_temp[rand_rows, ]
val_data = data_temp[-rand_rows, ]
##LOGISTISTIC
logit = glm(fmla, data = train_data, family = "binomial")
try({
prob_log = predict(logit, val_data, type = "response")
pred_log = prediction(prob_log, val_data$target) #create a prediction object with true values and predicted ones
roc.perf_log = performance(pred_log, measure = "tpr", x.measure = "fpr") #performance measure as ROC
auc.perf_log = performance(pred_log, measure = "auc") #performance measure AUC
auc_log[i] = auc.perf_log@y.values[[1]]
acc.perf_log = performance(pred_log, measure = "acc") # find best cutoff according to accuracy
ind_log = which.max( slot(acc.perf_log, "y.values")[[1]] )
acc_log[i] = slot(acc.perf_log, "y.values")[[1]][ind_log]
cutoff_log = slot(acc.perf_log, "x.values")[[1]][ind_log]
cut_log[i] = cutoff_log
pred_log = as.numeric(prob_log > cutoff_log) #ERROR- minimized by maximizing ACCURACY using its cutoff
er_log[i] = mean(pred_log != val_data$target)
},TRUE)
##DECISION TREE - BAGGED
m<-dim(train_data)[1]
ntree<-33
samples<-sapply(1:ntree,
FUN = function(iter)
{sample(1:m, size=m, replace=T)}) #replace=T makes it a bootstrap
try({
treelist<-lapply(1:ntree, #Training the individual decision trees and return them in a list
FUN=function(iter) {
samp <- samples[,iter];
rpart(fmla,train_data[samp,])
}
)
#predict.bag assumes the underlying classifier returns decision probabilities, not decisions.
predict.bag<-function(treelist,newdata) {
preds<-sapply(1:length(treelist),
FUN=function(iter) {
predict(treelist[[iter]],newdata=newdata)
}
)
predsums<-rowSums(preds)
predsums/length(treelist)
}
prob_bagtree = predict.bag(treelist, newdata=val_data)
pred_bagtree = prediction(prob_bagtree, val_data$target)
roc.perf_bagtree = performance(pred_bagtree, measure = "tpr", x.measure = "fpr") #performance measure as ROC
auc.perf_bagtree = performance(pred_bagtree, measure = "auc") #performance measure AUC
auc_cart[i] = auc.perf_bagtree@y.values[[1]]
acc.perf_bagtree = performance(pred_bagtree, measure = "acc") # find best cutoff according to accuracy
ind_bagtree = which.max( slot(acc.perf_bagtree, "y.values")[[1]] )
acc_cart[i] = slot(acc.perf_bagtree, "y.values")[[1]][ind_bagtree]
cutoff_bagtree = slot(acc.perf_bagtree, "x.values")[[1]][ind_bagtree]
cut_cart[i] = cutoff_bagtree
pred_bagtree = as.numeric(prob_bagtree > cutoff_bagtree) #ERROR- minimized by maximizing ACCURACY using its cutoff
er_cart[i] = mean(pred_bagtree != val_data$target)
},TRUE)
##NEURAL NET
nn = nnet(target~Ã¯..age+sex+cp+trestbps+chol+fbs+restecg+thalach
+exang+oldpeak+slope+ca+thal, data = train_data, size = 5, decay = 5e-4, maxit = 100)
try({
prob_nn = predict(nn, val_data)
pred_nn = prediction(prob_nn, val_data$target) #create a prediction object with true values and predicted ones
roc.perf_nn = performance(pred_nn, measure = "tpr", x.measure = "fpr") #performance measure as ROC
auc.perf_nn = performance(pred_nn, measure = "auc") #performance measure AUC
auc_nn[i] = auc.perf_nn@y.values[[1]]
acc.perf_nn = performance(pred_nn, measure = "acc") # find best cutoff according to accuracy
ind_nn = which.max( slot(acc.perf_nn, "y.values")[[1]] )
acc_nn[i] = slot(acc.perf_nn, "y.values")[[1]][ind_nn]
cutoff_nn = slot(acc.perf_nn, "x.values")[[1]][ind_nn]
cut_nn[i] = cutoff_nn
pred_nn = as.numeric(prob_nn > cutoff_nn) #ERROR- minimized by maximizing ACCURACY using its cutoff
er_nn[i] = mean(pred_nn != val_data$target)
},TRUE)
##BOOSTED TREE
sparse_matrix = sparse.model.matrix(target ~ ., data = train_data)[,-1] #dummy contrast coding of categorical variables to fit the xgboost
sparse_matrix_val = sparse.model.matrix(target ~ ., data = val_data[,colnames(train_data)])[,-1]
labels = train_data$target
bst = xgboost(data = sparse_matrix, label = labels, max_depth = 4,
eta = 1, nthread = 2, nrounds = 10,objective = "binary:logistic")
importance = xgb.importance(feature_names = colnames(sparse_matrix), model = bst) #importance of features
head(importance)
try({
prob_xgboost = predict(bst, sparse_matrix_val)
pred_xgboost = prediction(prob_xgboost, val_data$target) #create a prediction object with true values and predicted ones
roc.perf_xgboost = performance(pred_xgboost, measure = "tpr", x.measure = "fpr") #performance measure as ROC
auc.perf_xgboost= performance(pred_xgboost, measure = "auc") #performance measure AUC
auc_xgboost[i] = auc.perf_xgboost@y.values[[1]]
acc.perf_xgboost = performance(pred_xgboost, measure = "acc") # find best cutoff according to accuracy
ind_xgboost = which.max( slot(acc.perf_xgboost, "y.values")[[1]] )
acc_xgboost[i] = slot(acc.perf_xgboost, "y.values")[[1]][ind_xgboost]
cutoff_xgboost = slot(acc.perf_xgboost, "x.values")[[1]][ind_xgboost]
cut_xgboost[i] = cutoff_xgboost
pred_xgboost = as.numeric(prob_xgboost > cutoff_xgboost) #ERROR- minimized by maximizing ACCURACY using its cutoff
er_xgboost[i] = mean(pred_xgboost != val_data$target)
},TRUE)
}
print(mean(acc_log, na.rm = TRUE))
prob_log = predict(logit, val_data, type = "response")
pred_log = prediction(prob_log, val_data$target) #create a prediction object with true values and predicted ones
val_data$target
val_data
val_data$target = as.factor(val_data$target)
##LOGISTISTIC
logit = glm(fmla, data = train_data, family = "binomial")
try({
prob_log = predict(logit, val_data, type = "response")
pred_log = prediction(prob_log, val_data$target) #create a prediction object with true values and predicted ones
roc.perf_log = performance(pred_log, measure = "tpr", x.measure = "fpr") #performance measure as ROC
auc.perf_log = performance(pred_log, measure = "auc") #performance measure AUC
auc_log[i] = auc.perf_log@y.values[[1]]
acc.perf_log = performance(pred_log, measure = "acc") # find best cutoff according to accuracy
ind_log = which.max( slot(acc.perf_log, "y.values")[[1]] )
acc_log[i] = slot(acc.perf_log, "y.values")[[1]][ind_log]
cutoff_log = slot(acc.perf_log, "x.values")[[1]][ind_log]
cut_log[i] = cutoff_log
pred_log = as.numeric(prob_log > cutoff_log) #ERROR- minimized by maximizing ACCURACY using its cutoff
er_log[i] = mean(pred_log != val_data$target)
},TRUE)
prob_log = predict(logit, val_data, type = "response")
pred_log = prediction(prob_log, val_data$target) #create a prediction object with true values and predicted ones
val_data$target
pred_log = ROCR::prediction(prob_log, val_data$target) #create a prediction object with true values and predicted ones
library(ROCR)
library(party)
library(DiagrammeR)
library(GGally)
library(neuralnet)
library(foreign)
library(plyr)
library(MASS)
library(rms)
library(pROC)
library(rpart)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
library(e1071)
library(dplyr)
library(ggplot2)
library(tidyr)
library(tidyverse)
library(cluster)
library(factoextra)
library(xgboost)
library(Matrix)
library(mltools)
library(data.table)
library(DMwR)
library(zoo)
library(caret)
library(randomForest)
library(nnet)
library(ROCR)
pred_log = prediction(prob_log, val_data$target) #create a prediction object with true values and predicted ones
library(party)
