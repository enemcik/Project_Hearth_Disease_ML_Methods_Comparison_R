'Present.residence.since', 'Property', 'Age.in.years',
'Other.installment.plans', 'Housing',
'Number.of.existing.credits.at.this.bank', 'Job',
'Number.of.people.being.liable.to.provide.maintenance.for',
'Telephone', 'foreign.worker', 'Good.Loan')
d$Good.Loan<-as.factor(ifelse(d$Good.Loan==1,'GoodLoan','BadLoan'))
head(d,3) #Check the new structure
mapping<-list('A11'='... < 0 DM',
'A12'='0 <= ... < 200 DM',
'A13'='... >= 200 DM / salary assignments for at least 1 year',
'A14'='no checking account',
'A30'='no credits taken/all credits paid back duly',
'A31'='all credits at this bank paid back duly',
'A32'='existing credits paid back duly till now',
'A33'='delay in paying off in the past',
'A34'='critical account/other credits existing (not at this bank)',
'A40'='car (new)',
'A41'='car (used)',
'A42'='furniture/equipment',
'A43'='radio/television',
'A44'='domestic appliances',
'A45'='repairs',
'A46'='education',
'A47'='(vacation - does not exist?)',
'A48'='retraining',
'A49'='business',
'A410'='others',
'A61'='... < 100 DM',
'A62'='100 <= ... < 500 DM',
'A63'='500 <= ... < 1000 DM',
'A64'='.. >= 1000 DM',
'A65'='unknown/ no savings account',
'A71'='unemployed',
'A72'='... < 1 year',
'A73'='1 <= ... < 4 years',
'A74'='4 <= ... < 7 years',
'A75'='.. >= 7 years',
'A91'='male : divorced/separated',
'A92'='female : divorced/separated/married',
'A93'='male : single',
'A94'='male : married/widowed',
'A95'='female : single',
'A101'='none',
'A102'='co-applicant',
'A103'='guarantor',
'A121'='real estate',
'A122'='if not A121 : building society savings agreement/life insurance',
'A123'='if not A121/A122 : car or other, not in attribute 6',
'A124'='unknown / no property',
'A141'='bank',
'A142'='stores',
'A143'='none',
'A151'='rent',
'A152'='own',
'A153'='for free',
'A171'='unemployed/ unskilled - non-resident',
'A172'='unskilled - resident',
'A173'='skilled employee / official',
'A174'='management/ self-employed/highly qualified employee/ officer',
'A191'='none',
'A192'='yes, registered under the customers name',
'A201'='yes',
'A202'='no')
for(i in 1:(dim(d))[2]) {   #Repeat over all columns in the data frame d.
if(class(d[,i])=='character') { #For each column that has a character class
d[,i] <- as.factor(as.character(mapping[d[,i]])) #re-map the values
}
}
head(d,3) #Check how the data frame changed
table(d$Purpose,d$Good.Loan)
load('phsample.RData')
psub<-subset(dpus,with(dpus,(PINCP>1000)&(ESR==1)&
(PINCP<=250000)&(PERNP>1000)&(PERNP<=250000)&
(WKHP>=40)&(AGEP>=20)&(AGEP<=50)&
(PWGTP1>0)&(COW %in% (1:7))&(SCHL %in% (1:24))))
load('phsample.RData') #Assuming the file is in the working directory
#Selecting a subset of data rows matching detailed employment conditions
psub<-subset(dpus,with(dpus,(PINCP>1000)&(ESR==1)&
(PINCP<=250000)&(PERNP>1000)&(PERNP<=250000)&
(WKHP>=40)&(AGEP>=20)&(AGEP<=50)&
(PWGTP1>0)&(COW %in% (1:7))&(SCHL %in% (1:24))))
load("C:/Users/paulm/Desktop/Uni stuff/MA - 3.Sem/R for Datascientists/phsample.RData")
psub<-subset(dpus,with(dpus,(PINCP>1000)&(ESR==1)&
(PINCP<=250000)&(PERNP>1000)&(PERNP<=250000)&
(WKHP>=40)&(AGEP>=20)&(AGEP<=50)&
(PWGTP1>0)&(COW %in% (1:7))&(SCHL %in% (1:24))))
head(psub$SEX)
psub$SEX<-as.factor(ifelse(psub$SEX==1,'M','F')) #Reencode sex from 1/2 to M/F.
head(psub$SEX)
psub$SEX<-relevel(psub$SEX,'M') #Make the reference sex M, so F encodes a difference from M in models.
head(psub$SEX)
cowmap<-c("Employee of a private for-profit",
"Private not-for-profit employee",
"Local government employee",
"State government employee",
"Federal government employee",
"Self-employed not incorporated",
"Self-employed incorporated")
head(psub$COW,20)
psub$COW<-as.factor(cowmap[psub$COW])
head(psub$COW,20)
schlmap<-c(
rep("no high school diploma",15),
"Regular high school diploma",
"GED or alternative credential",
"some college credit, no degree",
"some college credit, no degree",
"Associate's degree",
"Bachelor's degree",
"Master's degree",
"Professional degree",
"Doctorate degree")
psub$SCHL<-as.factor(schlmap[psub$SCHL])
psub$SCHL<-relevel(psub$SCHL,schlmap[1])
dtrain<-subset(psub,ORIGRANDGROUP>=500) #Subset of data rows used for model training.
dtest<-subset(psub,ORIGRANDGROUP<500) #Subset of data rows used for model testing.
summary(dtrain$COW)
custdata<-read.table('custdata.tsv',
header=TRUE,sep='\t')
custdata<-read.table('custdata.tsv',
header=TRUE,sep='\t')
custdata<-read.table('custdata.tsv',
header=TRUE,sep='\t')
custdata<-read.table('custdata.tsv',
header=TRUE,sep='\t')
load("C:/Users/paulm/Desktop/Uni stuff/MA - 3.Sem/R for Datascientists/custdata.tsv")
load("exampleData.rData")
load("C:/Users/paulm/Desktop/Uni stuff/MA - 3.Sem/R for Datascientists/Week 05-06 - Code & Data/exampleData.rData")
summary(custdata[is.na(custdata$housing.type),
#Restrict to the rows where housing.type is NA.
c("recent.move","num.vehicles")]
#Look only at the columns recent.move and num.vehicles.
)
custdata$is.employed.fix<-ifelse(is.na(custdata$is.employed), #If is.employed value is missing...
"missing", #...assign the value "missing". Otherwise...
ifelse(custdata$is.employed==T, #...if is.employed==TRUE, assign the value "employed"...
"employed",
"not employed")) #...or the value "not employed".
#The transformation has turned the variable
#type from factor to string. It can be changed back
#with the as.factor() function.
summary(custdata$is.employed.fix)
summary(as.factor(custdata$is.employed.fix))
meanIncome<-mean(custdata$income,na.rm=T)
Income.fix<-ifelse(is.na(custdata$income), #Substitute the NAs with an average value
meanIncome,
custdata$income)
summary(Income.fix)
breaks<-c(0,10000,50000,100000,250000,1000000)
Income.groups<-cut(custdata$income,
breaks=breaks, include.lowest=T)
summary(Income.groups)
Income.groups<-as.character(Income.groups)
Income.groups<-ifelse(is.na(Income.groups),
"no income",Income.groups)
summary(as.factor(Income.groups))
missingIncome<-is.na(custdata$income)
Income.fix<-ifelse(is.na(custdata$income),0,custdata$income)
medianincome<-aggregate(income~state.of.res,custdata,FUN=median)
colnames(medianincome)<-c('State','Median.Income') #Rename the columns
summary(medianincome)
head(medianincome)
head(custdata)
custdata$Median.Income<-NULL
dim(custdata)[1]
dim(custdata)
install.packages(c("ROCR","class","rpart")) #Needed packages
spamD <- read.table('spamD.tsv',header=T,sep='\t') #Don't forget to set your working directory
spamTrain <- subset(spamD,spamD$rgroup>=10) #Defining a training sample
spamTest <- subset(spamD,spamD$rgroup<10) #Defining a testing sample
spamVars <- setdiff(colnames(spamD),list('rgroup','spam')) #Create a vector of variable names of independent variables, i.e. to be used in the model
spamFormula <- as.formula(paste('spam=="spam"', #Create a formula
load("C:/Users/paulm/Desktop/Uni stuff/MA - 3.Sem/R for Datascientists/Week 07 - Code & Data/spamD.tsv")
spamTrain <- subset(spamD,spamD$rgroup>=10) #Defining a training sample
spamTest <- subset(spamD,spamD$rgroup<10) #Defining a testing sample
spamVars <- setdiff(colnames(spamD),list('rgroup','spam')) #Create a vector of variable names of independent variables, i.e. to be used in the model
spamFormula <- as.formula(paste('spam=="spam"', #Create a formula
paste(spamVars,collapse=' + '), sep=' ~ '))
spamModel <- glm(spamFormula,family=binomial(link='logit'), #Estimate the logit model (we leave the details to the later weeks)
data=spamTrain)
spamTrain$pred <- predict(spamModel,newdata=spamTrain, #Get predictions (fitted values) for the training sample
type='response')
spamTest$pred <- predict(spamModel,newdata=spamTest, #Get predictions for the testing sample
type='response')
spamTrain <- subset(spamD,spamD$rgroup>=10) #Defining a training sample
load("C:/Users/paulm/Desktop/Uni stuff/MA - 3.Sem/R for Datascientists/Week 07 - Code & Data/spamD.tsv")
load("C:/Users/paulm/Desktop/Uni stuff/MA - 3.Sem/R for Datascientists/Week 11 & 12 - Code & Data/psub.RData")
dim(psub) #check number of observations and variables
names(psub) #check the names
hist(psub$ORIGRANDGROUP)
dtrain<-subset(psub,ORIGRANDGROUP>=500)
dtest<-subset(psub,ORIGRANDGROUP<500)
dim(dtrain)[2]/(dim(dtrain)[2]+dim(dtest)[2])
summary(psub$COW)
summary(psub$SCHL)
#Estimate the model on the dtrain data
model<-lm(log(PINCP,base=10)~AGEP+SEX+COW+SCHL,data=dtrain)
View(model)
dtest$predLogPINCP<-predict(model,newdata=dtest)
dtrain$predLogPINCP<-predict(model,newdata=dtrain)
R2<-function(y,pred) {
#Function is based on the standard definition of
#R2=1-SSR/SST
#For actual prediction (out-of-sample), SSR changes into
#the sum of squared prediction errors
1-sum((y-pred)^2)/sum((y-mean(y))^2)
R2<-function(y,pred) {
#Function is based on the standard definition of
#R2=1-SSR/SST
#For actual prediction (out-of-sample), SSR changes into
#the sum of squared prediction errors
1-sum((y-pred)^2)/sum((y-mean(y))^2)
}
R2(log(dtrain$PINCP,base=10),predict(model,newdata=dtrain))
#Out-of-sample R2
R2(log(dtest$PINCP,base=10),predict(model,newdata=dtest))
rmse<-function(y,pred) {
#An alternative measure of model quality
#Can be seen as a measure of the width of the data
#around the line of perfect prediction
sqrt(mean((y-pred)^2))
}
rmse(log(dtrain$PINCP,base=10),predict(model,newdata=dtrain))
rmse(log(dtest$PINCP,base=10),predict(model,newdata=dtest))
summary(model) #Interpret
summary(model)
)
model<-lm(log(PINCP,base=10)~AGEP+SEX+COW+SCHL,data=dtrain)
#Predict using the in-sample model for in-sample (dtrain) and out-of-sample (dtest) data
dtest$predLogPINCP<-predict(model,newdata=dtest)
dtrain$predLogPINCP<-predict(model,newdata=dtrain)
R2<-function(y,pred) {
#Function is based on the standard definition of
#R2=1-SSR/SST
#For actual prediction (out-of-sample), SSR changes into
#the sum of squared prediction errors
1-sum((y-pred)^2)/sum((y-mean(y))^2)
}
R2(log(dtrain$PINCP,base=10),predict(model,newdata=dtrain))
#Out-of-sample R2
R2(log(dtest$PINCP,base=10),predict(model,newdata=dtest))
rmse<-function(y,pred) {
#An alternative measure of model quality
#Can be seen as a measure of the width of the data
#around the line of perfect prediction
sqrt(mean((y-pred)^2))
}
rmse(log(dtrain$PINCP,base=10),predict(model,newdata=dtrain))
rmse(log(dtest$PINCP,base=10),predict(model,newdata=dtest))
summary(model) #Interpret
names(model)
names(summary(model)) #Values of lm() and summary(lm()) are a bit different
plot(model$fitted.values,log(dtrain$PINCP,base=10))
plot(predict(model,newdata=dtest),log(dtest$PINCP,base=10))
library(lars)
x<-model.matrix(log(PINCP,base=10)~AGEP+SEX+COW+SCHL,data=dtrain)
x<-x[,-1]
install.packages(lars)
#The model.matrix statement defines the model to be fitted
install.packages("lars")
library(lars)
x<-model.matrix(log(PINCP,base=10)~AGEP+SEX+COW+SCHL,data=dtrain)
x<-x[,-1]
lasso<-lars(x=x,y=log(dtrain$PINCP,base=10),trace=TRUE)
plot(lasso)
lasso
coef(lasso,s=c(.25,.50,0.75,1.0),mode="fraction") #coefficient values as functions of shrinkage
#Cross-validation using 100 folds
cv.lars(x=x,y=log(dtrain$PINCP,base=10),K=100)
xx<-model.matrix(log(PINCP,base=10)~AGEP*(SEX+COW+SCHL)^2,data=dtrain) #larger independent variables pool
xx<-xx[,-1]
dim(x)
dim(xx) #compare the number of independent variables
lasso_xx<-lars(x=xx,y=log(dtrain$PINCP,base=10),trace=FALSE)
coef(lasso_xx,s=seq(0,1,by=0.2),mode="fraction")
cv<-cv.lars(x=xx,y=log(dtrain$PINCP,base=10),K=33)
names(cv)
plot(cv$index,cv$cv,type="l")
lasso_xx<-lars(x=xx,y=log(dtrain$PINCP,base=10),trace=FALSE)
coef(lasso_xx,s=seq(0,1,by=0.2),mode="fraction")
cv<-cv.lars(x=xx,y=log(dtrain$PINCP,base=10),K=33)
names(cv)
plot(cv$index,cv$cv,type="l")
dtrain$predLogPINCP_LASSO<-predict(lasso_xx,xx,s=cv_min,mode="fraction")$fit
xx_pred<-model.matrix(log(PINCP,base=10)~AGEP*(SEX+COW+SCHL)^2,data=dtest)
xx_pred<-xx_pred[,-1]
dtest$predLogPINCP_LASSO<-predict(lasso_xx,xx_pred,s=cv_min,mode="fraction")$fit
plot(dtest$predLogPINCP,dtest$predLogPINCP_LASSO)
R2(log(dtrain$PINCP,base=10),dtrain$predLogPINCP)
R2(log(dtrain$PINCP,base=10),dtrain$predLogPINCP_LASSO)
R2(log(dtrain$PINCP,base=10),dtrain$predLogPINCP_OLS)
R2(log(dtest$PINCP,base=10),dtest$predLogPINCP)
R2(log(dtest$PINCP,base=10),dtest$predLogPINCP_LASSO)
R2(log(dtest$PINCP,base=10),dtest$predLogPINCP_OLS)
source('C:/Users/paulm/Desktop/Uni stuff/MA - 4. Sem/Datascience in R II/Code & Data 01/Code 01.R', encoding = 'UTF-8')
load("C:/Users/paulm/Desktop/Uni stuff/MA - 4. Sem/Datascience in R II/Code & Data 01/spamD.tsv")
setwd("C:/Users/paulm/Desktop/Uni stuff/MA - 4. Sem/Datascience in R II/Projekt/R_Project")
library(parallel)
library(parallelMap)
#library(party)
#library(DiagrammeR)
library(GGally)
library(neuralnet)
#library(foreign)
library(plyr)
library(MASS)
library(rms)
library(rpart)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
library(e1071)
library(dplyr)
library(ggplot2)
library(tidyr)
library(tidyverse)
library(cluster)
library(factoextra)
library(xgboost)
library(Matrix)
library(mltools)
library(data.table)
library(DMwR)
library(zoo)
library(caret)
library(randomForest)
library(nnet)
library(ROCR)
library(mlr)
data = read.csv("heart.csv")
data = as.data.frame(data)
head(data,5)
data$sex = as.factor(data$sex) #gender
data$cp = as.factor(data$cp) #chest pain
data$fbs = as.factor(data$fbs) #fasting blood sugar
data$restecg = as.factor(data$restecg) #resting ECG
data$exang = as.factor(data$exang) # induced angina
data$slope = as.factor(data$slope) #slope
data$ca = as.factor(data$ca) #number of colored vessels
data$thal = as.factor(data$thal) #thal
data$target = as.factor(data$target) #ou
str(data) #variables
summary(data) #variable statistics
sapply(data, sd)
apply(data, 2, function(x) {sum(is.na(x))}) #NAs inspection, 0 present
summary(data)
data_cv = data #cross-validation
summary(data_cv$target)
n = nrow(data) #shuffling the data
set.seed(104)
data = data[sample(n),]
set.seed(46)
rand_rows = sample(1:nrow(data), 0.6*nrow(data)) #split into training and validation dataset
train_data = data[rand_rows, ]
val_data = data[-rand_rows, ]
vars = colnames(data)[-length(colnames(data))] #creating a formula
y = "target"
fmla = paste(y, paste(vars, collapse="+"),sep="~")
fmla
opt.cut = function(perf, pred){ # function which finds optimal cutoff level maximizing a trade-off between Sensitivity& Specifivity
cut.ind = mapply(FUN=function(x, y, p){
d = (x - 0)^2 + (y-1)^2
ind = which(d == min(d))
c(sensitivity = y[[ind]], specificity = 1-x[[ind]],
cutoff = p[[ind]])
}, perf@x.values, perf@y.values, pred@cutoffs)
}
performanceMeasures<-function(prob, truth, name="model") { #Function for various accuracy measures we use.
pred= ROCR::prediction(prob, truth)
roc = ROCR::performance(pred, measure = "tpr", x.measure = "fpr") #performance measure as ROC
auc.perf= ROCR::performance(pred, measure = "auc") #performance measure AUC
auc= auc.perf@y.values[[1]]
sen_spe = opt.cut(roc, pred)
acc.perf = ROCR::performance(pred, measure = "acc") # find best cutoff according to accuracy
ind = which.max( slot(acc.perf, "y.values")[[1]] )
acc = slot(acc.perf, "y.values")[[1]][ind]
cutoff= slot(acc.perf, "x.values")[[1]][ind]
pred_cut = as.numeric(prob > cutoff) #ERROR- minimized by maximizing ACCURACY using its cutoff
er = mean(pred_cut != truth)
data.frame(model=name, Area_under_the_curve = auc, Sensitivity = sen_spe[1],
Specificity= sen_spe[2], Cutoff_Sen_Spe= sen_spe[3], Accuracy=acc, Cutoff_acc = cutoff, error=er)
}
logit = glm(fmla, data = train_data, family = "binomial")
prob_log_train = predict(logit, train_data, type = "response")
prob_log_test = predict(logit, val_data, type = "response")
perf_log_train = performanceMeasures(prob_log_train, train_data$target, name="Logit Training")
perf_log_train
perf_log_test = performanceMeasures(prob_log_test, val_data$target, name="Logit Testing")
perf_log_test
cart = rpart(fmla, data = train_data, method = 'class')
rpart.plot(cart)
prob_cart_train = predict(cart, train_data)
prob_cart_test = predict(cart, val_data) #prediction
perf_cart_train = performanceMeasures(prob_cart_train[,2], train_data$target, name="DECISION TREES Training")
perf_cart_train
perf_cart_test = performanceMeasures(prob_cart_test[,2], val_data$target, name="DECISION TREES Testing")
perf_cart_test
set.seed(69)
nn = nnet(target~ï..age+sex+cp+trestbps+chol+fbs+restecg+thalach
+exang+oldpeak+slope+ca+thal, data = train_data, size = 5, decay = 5e-4, maxit = 100)
prob_nn_train = predict(nn, train_data)
prob_nn_test = predict(nn, val_data) #prediction
perf_nn_train = performanceMeasures(prob_nn_train, train_data$target, name="NEURAL NETWORKS Training")
perf_nn_train
perf_nn_test = performanceMeasures(prob_nn_test, val_data$target, name="NEURAL NETWORKS Testing")
perf_nn_test
m<-dim(train_data)[1]
ntree<-500
set.seed(65)
samples<-sapply(1:ntree,
FUN = function(iter)
{sample(1:m, size=m, replace=T)}) #replace=T makes it a bootstrap
treelist<-lapply(1:ntree, #Training the individual decision trees and return them in a list
FUN=function(iter) {
samp <- samples[,iter];
rpart(fmla,train_data[samp,], method= "class")
}
)
#predict.bag assumes the underlying classifier returns decision probabilities, not decisions.
predict.bag<-function(treelist,newdata) {
preds<-lapply(1:length(treelist),
FUN=function(iter) {
predict(treelist[[iter]],newdata=newdata)
}
)
preds
}
prob_bagtree_train = predict.bag(treelist, newdata=train_data)
prob_bagtree_train= as.data.frame(prob_bagtree_train)
prob_bagtree_train_1= rowSums(prob_bagtree_train[, seq(2, ncol(prob_bagtree_train), 2)])/length(treelist)
prob_bagtree_test = predict.bag(treelist, newdata=val_data)
prob_bagtree_test= as.data.frame(prob_bagtree_test)
prob_bagtree_test_1= rowSums(prob_bagtree_test[, seq(2, ncol(prob_bagtree_test), 2)])/length(treelist)
perf_bagtree_train = performanceMeasures(prob_bagtree_train_1, train_data$target, name="Bagged Trees Training")
perf_bagtree_train
perf_bagtree_test = performanceMeasures(prob_bagtree_test_1, val_data$target, name="Bagged Trees Testing")
perf_bagtree_test
set.seed(87)
rf = randomForest(as.factor(target)~ï..age+sex+cp+trestbps+chol+fbs+restecg+thalach
+exang+oldpeak+slope+ca+thal, nodesize = 1 ,data = train_data, proximity = TRUE)
prob_rf_train = predict(rf, train_data, type='prob') # returns probabilities not 0,1 values with type="prob"
prob_rf_test = predict(rf, val_data, type='prob')
perf_rf_train = performanceMeasures(prob_rf_train[,2], train_data$target, name="RANDOM FOREST Training")
perf_rf_train
perf_rf_test = performanceMeasures(prob_rf_test[,2], val_data$target, name="RANDOM FOREST Testing")
perf_rf_test
k = 100
prob_log_train =  NULL
prob_log_test = NULL
perf_log_train= as.data.frame( matrix(0, ncol = 0, nrow = 0))
perf_log_test=as.data.frame( matrix(0, ncol = 0, nrow = 0))
prob_cart_train= NULL
prob_cart_test= NULL
perf_cart_train= as.data.frame( matrix(0, ncol = 0, nrow = 0))
perf_cart_test=as.data.frame( matrix(0, ncol = 0, nrow = 0))
prob_nn_train= NULL
prob_nn_test= NULL
perf_nn_train= as.data.frame( matrix(0, ncol = 0, nrow = 0))
perf_nn_test=as.data.frame( matrix(0, ncol = 0, nrow = 0))
prob_rf_train= NULL
prob_rf_test= NULL
perf_rf_train= as.data.frame( matrix(0, ncol = 0, nrow = 0))
perf_rf_test=as.data.frame( matrix(0, ncol = 0, nrow = 0))
prob_bagtree_train= NULL
prob_bagtree_test= NULL
perf_bagtree_train= as.data.frame( matrix(0, ncol = 0, nrow = 0))
perf_bagtree_test=as.data.frame( matrix(0, ncol = 0, nrow = 0))
for (i in 1:k){ #sample randomly 100 times
n = nrow(data_cv)
data_temp = data_cv[sample(n),]
rand_rows = sample(1:nrow(data_temp), 0.7*nrow(data_temp)) #split into training and validation dataset
train_data = data_temp[rand_rows, ]
val_data = data_temp[-rand_rows, ]
##LOGISTISTIC ##DONE
logit = glm(fmla, data = train_data, family = "binomial")
try({
prob_log_train = predict(logit, train_data, type = "response")
prob_log_test = predict(logit, val_data, type = "response")
perf_log_train = rbind(perf_log_train, performanceMeasures(prob_log_train, train_data$target, name="Logit Training"))
perf_log_test = rbind(perf_log_test,performanceMeasures(prob_log_test, val_data$target, name="Logit Testing"))
},TRUE)
cart = rpart(fmla, data = train_data, method = 'class')
try({
prob_cart_train = predict(cart, train_data)
prob_cart_test = predict(cart, val_data) #prediction
perf_cart_train = rbind(perf_cart_train,performanceMeasures(prob_cart_train[,2], train_data$target, name="DECISION TREES Training"))
perf_cart_test =rbind(perf_cart_test, performanceMeasures(prob_cart_test[,2], val_data$target, name="DECISION TREES Testing"))
},TRUE)
nn = nnet(target~ï..age+sex+cp+trestbps+chol+fbs+restecg+thalach
+exang+oldpeak+slope+ca+thal, data = train_data, size = 5, decay = 5e-4, maxit = 100)
try({
prob_nn_train = predict(nn, train_data)
prob_nn_test = predict(nn, val_data) #prediction
perf_nn_train =rbind(perf_nn_train, performanceMeasures(prob_nn_train, train_data$target, name="NEURAL NETWORKS Training"))
perf_nn_test = rbind(perf_nn_test, performanceMeasures(prob_nn_test, val_data$target, name="NEURAL NETWORKS Testing"))
},TRUE)
rf = randomForest(as.factor(target)~ï..age+sex+cp+trestbps+chol+fbs+restecg+thalach
+exang+oldpeak+slope+ca+thal, nodesize = 1 ,data = train_data, proximity = TRUE)
try({
prob_rf_train = predict(rf, train_data, type='prob') # returns probabilities not 0,1 values with type="prob"
prob_rf_test = predict(rf, val_data, type='prob')
perf_rf_train = rbind(perf_rf_train,performanceMeasures(prob_rf_train[,2], train_data$target, name="RANDOM FOREST Training"))
perf_rf_test = rbind(perf_rf_test,performanceMeasures(prob_rf_test[,2], val_data$target, name="RANDOM FOREST Testing"))
},TRUE)
}
summary(perf_log_train)
summary(perf_log_test)
perf_rf_test
summary(perf_nn_test)
summary(perf_rf_test)
perf_log_test
summary(perf_log_test)
